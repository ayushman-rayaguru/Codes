# -*- coding: utf-8 -*-
"""DIVP_ALL_Labs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BjMwSH5RGJ_4UtuQF5Xe7y0zIdMrGiyC

## ***EXP 1*** **PERFORM  BASIC  OPERATIONS  ON  AN  IMAGE**
"""





"""## *1.	Basic logical operations on an image (AND , XOR, OR)*"""

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img1 = mpimg.imread('img1.bmp')
img2 = mpimg.imread('img2.bmp')
plt.subplot(121)
plt.imshow(img1)
plt.subplot(122)
plt.imshow(img2)

"""### *bitwise_and*"""

from google.colab.patches import cv2_imshow

img1 = cv2.imread("img1.bmp")
img2 = cv2.imread("img2.bmp")
bitwise_and = cv2.bitwise_and(img2, img1)
cv2_imshow(bitwise_and)

"""### *bitwise_or*"""

img1 = cv2.imread("img1.bmp")
img2 = cv2.imread("img2.bmp")
bitwise_or = cv2.bitwise_or(img2, img1)
cv2_imshow(bitwise_or)

"""### *bitwise_xor*"""

img1 = cv2.imread("img1.bmp")
img2 = cv2.imread("img2.bmp")
bitwise_xor = cv2.bitwise_xor(img2, img1)
cv2_imshow(bitwise_xor)

"""## *2. Basic arithmetic operations on an image (Add , Subtract, Multiply, Divide)*

"""

img3 = mpimg.imread('img3.jpg')
img4 = mpimg.imread('img4.jpg')
plt.subplot(121)
plt.imshow(img3)
plt.subplot(122)
plt.imshow(img4)

"""### *Add operation*"""

import numpy as np
import cv2 
img3 = cv2.imread('img3.jpg') 
img4 = cv2.imread('img4.jpg')
img3 = cv2.resize(img3,(512,512))
img4 = cv2.resize(img4,(512,512))
res1 = cv2.add(img3,img4)
cv2_imshow(res1)

"""### *Subtract operation*"""

img3 = cv2.imread('img3.jpg') 
img4 = cv2.imread('img4.jpg')
img3 = cv2.resize(img3,(512,512))
img4 = cv2.resize(img4,(512,512))
res2 = cv2.subtract(img3,img4)
cv2_imshow(res2)

"""### *Multiply operation*"""

img3 = cv2.imread('img3.jpg') 
img4 = cv2.imread('img4.jpg')
img3 = cv2.resize(img3,(512,512))
img4 = cv2.resize(img4,(512,512))
res3 = cv2.multiply(img3,img4)
cv2_imshow(res3)

"""### *Divison operation*"""

img3 = cv2.imread('img3.jpg') 
img4 = cv2.imread('img4.jpg')
img3 = cv2.resize(img3,(512,512))
img4 = cv2.resize(img4,(512,512))
res4 = cv2.divide(img3,img4)
cv2_imshow(res4)

"""## *3. Negative of an image*"""

import cv2
import matplotlib.pyplot as plt
  
  
# Read an image
img_bgr = cv2.imread('img3.jpg', 1)
plt.imshow(img_bgr)
plt.show()
  
# Histogram plotting of the image
color = ('b', 'g', 'r')
  
for i, col in enumerate(color):
      
    histr = cv2.calcHist([img_bgr], 
                         [i], None,
                         [256], 
                         [0, 256])
      
    plt.plot(histr, color = col)
      
    # Limit X - axis to 256
    plt.xlim([0, 256])
      
plt.show()
  
# get height and width of the image
height, width, _ = img_bgr.shape
  
for i in range(0, height - 1):
    for j in range(0, width - 1):
          
        # Get the pixel value
        pixel = img_bgr[i, j]
          
        # Negate each channel by 
        # subtracting it from 255
          
        # 1st index contains red pixel
        pixel[0] = 255 - pixel[0]
          
        # 2nd index contains green pixel
        pixel[1] = 255 - pixel[1]
          
        # 3rd index contains blue pixel
        pixel[2] = 255 - pixel[2]
          
        # Store new values in the pixel
        img_bgr[i, j] = pixel
  
# Display the negative transformed image
plt.imshow(img_bgr)
plt.show()
  
# Histogram plotting of the
# negative transformed image
color = ('b', 'g', 'r')
  
for i, col in enumerate(color):
      
    histr = cv2.calcHist([img_bgr], 
                         [i], None,
                         [256],
                         [0, 256])
      
    plt.plot(histr, color = col)
    plt.xlim([0, 256])
      
plt.show()

"""## 4. *Log Transformation*"""

import cv2
image = cv2.imread('img5.jpg')
   
# Apply log transformation method
c = 255 / np.log(1 + np.max(image))
log_image = c * (np.log(image + 1))
   
# Specify the data type so that
# float value will be converted to int
log_image = np.array(log_image, dtype = np.uint8)

plt.imshow(image)
plt.show()
plt.imshow(log_image)
plt.show()

"""## 5. *Power Law(Gamma Transfromation)*"""

import cv2
import numpy as np
  
# Open the image.
img = cv2.imread('img6.jpg')
  
# Trying 4 gamma values.
for gamma in [0.1,2.2]:
      
    # Apply gamma correction.
    gamma_corrected = np.array(255*(img / 255) ** gamma, dtype = 'uint8')
  
    # Save edited images.
    cv2_imshow(gamma_corrected)

"""## 6. *Contrast Streching*"""

import cv2
import numpy as np

img = cv2.imread('img7.jpg')
original = img.copy()
xp = [0, 64, 128, 192, 255]
fp = [0, 16, 128, 240, 255]
x = np.arange(256)
table = np.interp(x, xp, fp).astype('uint8')
img = cv2.LUT(img, table)
cv2_imshow(original)
cv2_imshow(img)

"""## 7. *Bit Plane Slicing*"""

import cv2
# Read the image in greyscale
img = cv2.imread('img8.jpg',0)
 
#Iterate over each pixel and change pixel value to binary using np.binary_repr() and store it in a list.
lst = []
for i in range(img.shape[0]):
    for j in range(img.shape[1]):
         lst.append(np.binary_repr(img[i][j] ,width=8)) # width = no. of bits

four_bit_img = (np.array([int(i[4]) for i in lst],dtype = np.uint8) * 8).reshape(img.shape[0],img.shape[1])
two_bit_img = (np.array([int(i[6]) for i in lst],dtype = np.uint8) * 2).reshape(img.shape[0],img.shape[1])
one_bit_img = (np.array([int(i[7]) for i in lst],dtype = np.uint8) * 1).reshape(img.shape[0],img.shape[1])
five_bit_img = (np.array([int(i[3]) for i in lst],dtype = np.uint8) * 16).reshape(img.shape[0],img.shape[1])
three_bit_img = (np.array([int(i[5]) for i in lst],dtype = np.uint8) * 4).reshape(img.shape[0],img.shape[1])
eight_bit_img = (np.array([int(i[0]) for i in lst],dtype = np.uint8) * 128).reshape(img.shape[0],img.shape[1])
seven_bit_img = (np.array([int(i[1]) for i in lst],dtype = np.uint8) * 64).reshape(img.shape[0],img.shape[1])
six_bit_img = (np.array([int(i[2]) for i in lst],dtype = np.uint8) * 32).reshape(img.shape[0],img.shape[1])

final1 = cv2.hconcat([one_bit_img,two_bit_img,three_bit_img])
final2 = cv2.hconcat([four_bit_img,five_bit_img,six_bit_img])
final3 = cv2.hconcat([seven_bit_img,eight_bit_img])

final = cv2.vconcat([final1,final2])
cv2_imshow(img)
cv2_imshow(255-final)
cv2_imshow(final3)

"""## 8. *Gray-Level Slicing*"""

import cv2
import numpy as np

img = cv2.imread('img9.jpg',0) 
m,n = img.shape
T1 = 100
T2 = 180 
  
img_thresh_back = np.zeros((m,n), dtype = int)
   
for i in range(m):
      
    for j in range(n):
        if T1 < img[i,j] < T2: 
          img_thresh_back[i,j]= 255
        else:
          img_thresh_back[i,j] = img[i,j]
  
# Convert array to  png image
cv2_imshow(img)
cv2_imshow(img_thresh_back)

"""## ***EXP 2*** **PERFORM  CONVERSION  BETWEEN  COLOUR  SPACES**"""

import cv2

# import numpy library as np
import numpy as np

img10 = cv2.imread('img10.jpg')

# displaying the image using imshow() function of cv2
# In this : 1st argument is name of the frame
# 2nd argument is the image matrix
cv2_imshow(img10)

# shape attribute of an image matrix gives the dimensions
row,col,plane = img10.shape

# here image is of class 'uint8', the range of values  
# that each colour component can have is [0 - 255]

# create a zero matrix of order same as
# original image matrix order of same dimension
imgb = np.zeros((row,col,plane),np.uint8)

# store blue plane contents or data of image matrix
# to the corresponding plane(blue) of temp matrix
imgb[:,:,0] = img10[:,:,0]

# displaying the Blue plane image
cv2_imshow(imgb)

# again take a zero matrix of image matrix shape
imgg = np.zeros((row,col,plane),np.uint8)

# store green plane contents or data of image matrix
# to the corresponding plane(green) of temp matrix
imgg[:,:,1] = img10[:,:,1]

# displaying the Green plane image
cv2_imshow(imgg)

# again take a zero matrix of image matrix shape
imgr = np.zeros((row,col,plane),np.uint8)

# store red plane contents or data of image matrix
# to the corresponding plane(red) of temp matrix
imgr[:,:,2] = img10[:,:,2]

# displaying the Red plane image
cv2_imshow(imgr)

# RGB to HSI
import cv2
img=cv2.imread('img10.jpg')
img_HSV=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
cv2_imshow(img_HSV)
#'hue channel',
cv2_imshow(img_HSV[:,:,0])
#'saturation channel',
cv2_imshow(img_HSV[:,:,1])
#'value channel',
cv2_imshow(img_HSV[:,:,2])

# RGB to yiq
import cv2
from PIL import Image, ImageDraw
import numpy as np
img10 = cv2.imread('img10.jpg')
cv2_imshow(img10)
row,col,plane = img10.shape
imgb = np.zeros((row,col,plane),np.uint8)
imgb[:,:,0] = img10[:,:,0]
imgg = np.zeros((row,col,plane),np.uint8)
imgg[:,:,1] = img10[:,:,1]
imgr = np.zeros((row,col,plane),np.uint8)
imgr[:,:,2] = img10[:,:,2]
imgy=(0.3*imgr)+(0.59*imgg)+(0.11*imgb)
#Y
cv2_imshow(imgy)
imgi=(0.6*imgr)-(0.28*imgg)-(0.32*imgb)
#I
cv2_imshow(imgi)
imgq=(0.21*imgr)-(0.52*imgg)+(0.31*imgb)
#Q
cv2_imshow(imgq)
yiq=cv2.add(imgy, imgi, imgq)
#yiq
cv2_imshow( yiq)

#RGB to cmyk
import cv2
from PIL import Image, ImageDraw
import numpy as np
img10 = cv2.imread('img10.jpg')
cv2_imshow(img10)
row,col,plane = img10.shape
imgb = np.zeros((row,col,plane),np.uint8)
imgb[:,:,0] = img10[:,:,0]
#B
cv2_imshow(imgb)
imgg = np.zeros((row,col,plane),np.uint8)
imgg[:,:,1] = img10[:,:,1]
#G
cv2_imshow(imgg)
imgr = np.zeros((row,col,plane),np.uint8)
imgr[:,:,2] = img10[:,:,2]
#R
cv2_imshow(imgr)
rgb=cv2.add(imgr, imgg, imgb)
#RGB
cv2_imshow(rgb)



"""# ***EXP 3 Histogram Equalization***

### 3.1 Plotting histogram of dark, bright, low-contrast, high-contrast images
"""

from google.colab.patches import cv2_imshow
import cv2
import numpy as np
from matplotlib import pyplot as plt

images =['img11.jpg','img12.jpg','img13.jpg','img14.jpg']
for x in images:
  img = cv2.imread(x,0)

  hist,bins = np.histogram(img.flatten(),256,[0,256])

  cdf = hist.cumsum()
  cdf_normalized = cdf * hist.max()/ cdf.max()

  #plt.plot(cdf_normalized, color = 'b')
  plt.hist(img.flatten(),256,[0,256], color = 'r')
  plt.xlim([0,256])
  #plt.legend(('cdf','histogram'), loc = 'upper left')
  plt.legend(('histogram'), loc = 'upper left')
  plt.show()
  cv2_imshow(img)

"""### 3.2 Histogram Equalization & Colour Histogram

#### *We will equalize low contrast image and plot its histogram.*
"""

img = cv2.imread('img13.jpg',0)
equ = cv2.equalizeHist(img)
res = np.hstack((img,equ)) #stacking images side-by-side
cv2.imwrite('img13eq.jpg',res)
cv2_imshow(res)

images =['img13.jpg','img13eq.jpg']
lbl = ['Low contrast image Histogram','Equalized Image Histogram']
i = 0
for x in images:
  img = cv2.imread(x,0)
  hist,bins = np.histogram(img.flatten(),256,[0,256])
  plt.hist(img.flatten(),256,[0,256], color = 'r')
  plt.xlim([0,256])
  plt.legend((lbl[i]), loc = 'upper left')
  plt.title(lbl[i])
  plt.show()
  i = i+1

"""### Colour Histogram"""

import cv2
import numpy as np
from matplotlib import pyplot as plt

img = 'img15.jpg'
img15 = cv2.imread(img)
color = ('b','g','r')
plt.figure()
for i,col in enumerate(color):
    histr = cv2.calcHist([img15],[i],None,[256],[0,256])
    plt.plot(histr,color = col)
    plt.xlim([0,256])
    plt.legend(('blue','green','red'),loc = "upper left")
cv2_imshow(img15)
plt.show()

"""# ***EXP 4 Spatial Domain Filtering***"""

from google.colab.patches import cv2_imshow
import cv2
from PIL import Image, ImageDraw
# Load image:
input_image = Image.open("img8.jpg")
input_pixels = input_image.load()
# Box Blur kernel 3x3
box_kernel_3 = [[1 / 9, 1 / 9, 1 / 9],
              [1 / 9, 1 / 9, 1 / 9],
              [1 / 9, 1 / 9, 1 / 9]]
# Box Blur kernel 5x5
box_kernel_5 = [[1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25],
              [1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25],
              [1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25],
              [1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25],
              [1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25]]
# Weighted filter kernel 
weighted = [[1 / 16, 2 / 16, 1 / 16],
          [2 / 16, 4 / 16, 2 / 16],
          [1 / 16, 2 / 16, 1 / 16]]
# Select kernel here:
print('Enter number to select kernel')
print('1 : 3x3 Box Filter')
print('2 : 5x5 Box Filter')
print('3 : Weighted Filter')
choice=input()
if(choice=='1'):
    kernel = box_kernel_3
elif(choice=='2'):
    kernel= box_kernel_5
elif(choice=='3'):
    kernel= weighted
# Middle of the kernel
offset = len(kernel) // 2
# Create output image
output_image = Image.new("RGB", input_image.size)
draw = ImageDraw.Draw(output_image)
# Compute convolution between intensity and kernels
for x in range(offset, input_image.width - offset):
    for y in range(offset, input_image.height - offset):
        acc = [0, 0, 0]
        for a in range(len(kernel)):
            for b in range(len(kernel)):
                xn = x + a - offset
                yn = y + b - offset
                pixel = input_pixels[xn, yn]
                acc[0] += pixel[0] * kernel[a][b]
                acc[1] += pixel[1] * kernel[a][b]
                acc[2] += pixel[2] * kernel[a][b]
        draw.point((x, y), (int(acc[0]), int(acc[1]), int(acc[2])))
output_image.save("img8op.jpg")
img8wt = cv2.imread("img8op.jpg")
cv2_imshow(img8wt)

import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt
img = cv.imread('img21.jpg')
median = cv2.medianBlur(img,5)
plt.figure(figsize=(14,7), dpi=80)
plt.subplot(121), plt.imshow(img), plt.axis('off'), plt.title('Original image', size=20)
plt.subplot(122), plt.imshow(median), plt.axis('off'), plt.title('After Median filter', size=20)
plt.show()

from PIL import Image, ImageDraw
import numpy as np
import cv2
import matplotlib.pyplot as plt
# A = input('Enter value of A :')
input_image = Image.open("img20.jpg")
input_pixels = input_image.load()
kernel = [[-1 , -1 , -1 ],
              [-1 , 8 , -1],
              [-1 , -1 , -1]]
offset = len(kernel) // 2# Middle of the kernel
# Create output image
output_image = Image.new("RGB", input_image.size)
draw = ImageDraw.Draw(output_image)
# Compute convolution between intensity and kernels
for x in range(offset, input_image.width - offset):
    for y in range(offset, input_image.height - offset):
        acc = [0, 0, 0]
        for a in range(len(kernel)):
            for b in range(len(kernel)):
                xn = x + a - offset
                yn = y + b - offset
                pixel = input_pixels[xn, yn]
                acc[0] += pixel[0] * kernel[a][b]
                acc[1] += pixel[1] * kernel[a][b]
                acc[2] += pixel[2] * kernel[a][b]
        draw.point((x, y), (int(acc[0]), int(acc[1]), int(acc[2])))
output_image.save("img20Lap.jpg")
img1 = cv2.imread('img20.jpg') 
img2 = cv2.imread('img20Lap.jpg')
laplacian = cv2.add(img1,img2)
plt.figure(figsize=(21,7), dpi=80)
plt.subplot(131), plt.imshow(input_image), plt.axis('off'), plt.title('Original image', size=20)
plt.subplot(132), plt.imshow(img2), plt.axis('off'), plt.title('Laplacian Filter', size=20)
plt.subplot(133), plt.imshow(laplacian), plt.axis('off'), plt.title('Sharpened image + Original', size=20)
plt.show()

#High boost
from google.colab.patches import cv2_imshow
from PIL import Image, ImageDraw
# Load image:
input_image = Image.open("img22.jpg")
input_pixels = input_image.load()
A = float(input('Enter value of A :'))
kernel = [[-1 , -1 , -1 ],
              [-1 , A+8 , -1],
              [-1 , -1 , -1]]
offset = len(kernel) // 2# Middle of the kernel
# Create output image
output_image = Image.new("RGB", input_image.size)
draw = ImageDraw.Draw(output_image)
# Compute convolution between intensity and kernels
for x in range(offset, input_image.width - offset):
    for y in range(offset, input_image.height - offset):
        acc = [0, 0, 0]
        for a in range(len(kernel)):
            for b in range(len(kernel)):
                xn = x + a - offset
                yn = y + b - offset
                pixel = input_pixels[xn, yn]
                acc[0] += pixel[0] * kernel[a][b]
                acc[1] += pixel[1] * kernel[a][b]
                acc[2] += pixel[2] * kernel[a][b]
        draw.point((x, y), (int(acc[0]), int(acc[1]), int(acc[2])))
output_image.save("img22HighBoost.jpg")
res = cv2.imread("img22HighBoost.jpg")
cv2_imshow(res)

import cv2

def highBoostFiltering(image,boost_factor):
    
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #Converting Image to Gray Scale
    resultant_image = image.copy()
    for i in range(1,image.shape[0]-1):
        for j in range(1,image.shape[1]-1):
            blur_factor = float((image[i-1, j-1] + image[i-1, j] - image[i-1, j+1] + image[i, j-1] + image[i, j] + image[i, j+1] + image[i+1, j+1] + image[i+1, j] + image[i+1, j+1])/9)
            mask = boost_factor * image[i, j] - blur_factor
            resultant_image[i, j] = image[i, j] + mask
            
    return resultant_image

img = cv2.imread('img22.jpg')
factor = float(input('Enter the value of Filter Factor for High-Boost Filtering : '))
output = highBoostFiltering(img, factor)
cv2_imshow(output)

"""# ***EXP 5 Frequency Domain filtering***"""

import cv2
from matplotlib import pyplot as plt
import numpy as np


img = cv2.imread('img23.jpg', 0) # load an image


dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)

dft_shift = np.fft.fftshift(dft)

magnitude_spectrum = 20 * np.log(cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]))


# HPF

rows, cols = img.shape
crow, ccol = int(rows / 2), int(cols / 2)

mask = np.ones((rows, cols, 2), np.uint8)
r = 80
center = [crow, ccol]
x, y = np.ogrid[:rows, :cols]
mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r*r
mask[mask_area] = 0

#LPF

rows1, cols1 = img.shape
crow1, ccol1 = int(rows1 / 2), int(cols1 / 2)
mask1 = np.zeros((rows1, cols1, 2), np.uint8)
r1 = 100
center1 = [crow1, ccol1]
x1, y1 = np.ogrid[:rows1, :cols1]
mask_area1 = (x1 - center1[0]) ** 2 + (y1 - center1[1]) ** 2 <= r1*r1
mask1[mask_area1] = 1

fshift = dft_shift * mask


fshift_mask_mag = 20 * np.log(cv2.magnitude(fshift[:, :, 0], fshift[:, :, 1]))


f_ishift = np.fft.ifftshift(fshift)

img_back = cv2.idft(f_ishift)


img_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])



fshift1 = dft_shift * mask1


fshift_mask_mag1 = 20 * np.log(cv2.magnitude(fshift1[:, :, 0], fshift1[:, :, 1]))

f_ishift1 = np.fft.ifftshift(fshift1)


img_back1 = cv2.idft(f_ishift1)


img_back1 = cv2.magnitude(img_back1[:, :, 0], img_back1[:, :, 1])

fig = plt.figure(figsize=(12, 12))
ax1 = fig.add_subplot(3,2,1)
ax1.imshow(img, cmap='gray')
ax1.title.set_text('Input Image')
ax2 = fig.add_subplot(3,2,2)
ax2.imshow(magnitude_spectrum, cmap='gray')
ax2.title.set_text('FFT of image')
ax3 = fig.add_subplot(3,2,3)
ax3.imshow(fshift_mask_mag, cmap='gray')
ax3.title.set_text('HPF FFT + Mask')
ax4 = fig.add_subplot(3,2,4)
ax4.imshow(img_back, cmap='gray')
ax4.title.set_text('After HPF Filter')
ax3 = fig.add_subplot(3,2,5)
ax3.imshow(fshift_mask_mag1, cmap='gray')
ax3.title.set_text('LPF FFT + Mask')
ax4 = fig.add_subplot(3,2,6)
ax4.imshow(img_back1, cmap='gray')
ax4.title.set_text('After LPF Filter')
plt.show()

"""##Explaination..exp5"""

import cv2
from matplotlib import pyplot as plt
import numpy as np


img = cv2.imread('img23.jpg', 0) # load an image

#Output is a 2D complex array. 1st channel real and 2nd imaginary
#For fft in opencv input image needs to be converted to float32
dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)

#Rearranges a Fourier transform X by shifting the zero-frequency 
#component to the center of the array.
#Otherwise it starts at the tope left corenr of the image (array)
dft_shift = np.fft.fftshift(dft)

##Magnitude of the function is 20.log(abs(f))
#For values that are 0 we may end up with indeterminate values for log. 
#So we can add 1 to the array to avoid seeing a warning. 
magnitude_spectrum = 20 * np.log(cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]))


# Circular HPF mask, center circle is 0, remaining all ones
#Can be used for edge detection because low frequencies at center are blocked
#and only high frequencies are allowed. Edges are high frequency components.
#Amplifies noise.

rows, cols = img.shape
crow, ccol = int(rows / 2), int(cols / 2)

mask = np.ones((rows, cols, 2), np.uint8)
r = 80
center = [crow, ccol]
x, y = np.ogrid[:rows, :cols]
mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r*r
mask[mask_area] = 0


# Circular LPF mask, center circle is 1, remaining all zeros
# Only allows low frequency components - smooth regions
#Can smooth out noise but blurs edges.
#

rows1, cols1 = img.shape
crow1, ccol1 = int(rows1 / 2), int(cols1 / 2)
mask1 = np.zeros((rows1, cols1, 2), np.uint8)
r1 = 100
center1 = [crow1, ccol1]
x1, y1 = np.ogrid[:rows1, :cols1]
mask_area1 = (x1 - center1[0]) ** 2 + (y1 - center1[1]) ** 2 <= r1*r1
mask1[mask_area1] = 1



# apply mask and inverse DFT: Multiply fourier transformed image (values)
#with the mask values. 
fshift = dft_shift * mask

#Get the magnitude spectrum (only for plotting purposes)
fshift_mask_mag = 20 * np.log(cv2.magnitude(fshift[:, :, 0], fshift[:, :, 1]))

#Inverse shift to shift origin back to top left.
f_ishift = np.fft.ifftshift(fshift)

#Inverse DFT to convert back to image domain from the frequency domain. 
#Will be complex numbers
img_back = cv2.idft(f_ishift)

#Magnitude spectrum of the image domain
img_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])


# apply mask and inverse DFT: Multiply fourier transformed image (values)
#with the mask values. 
fshift1 = dft_shift * mask1

#Get the magnitude spectrum (only for plotting purposes)
fshift_mask_mag1 = 20 * np.log(cv2.magnitude(fshift1[:, :, 0], fshift1[:, :, 1]))

#Inverse shift to shift origin back to top left.
f_ishift1 = np.fft.ifftshift(fshift1)

#Inverse DFT to convert back to image domain from the frequency domain. 
#Will be complex numbers
img_back1 = cv2.idft(f_ishift1)

#Magnitude spectrum of the image domain
img_back1 = cv2.magnitude(img_back1[:, :, 0], img_back1[:, :, 1])

fig = plt.figure(figsize=(12, 12))
ax1 = fig.add_subplot(3,2,1)
ax1.imshow(img, cmap='gray')
ax1.title.set_text('Input Image')
ax2 = fig.add_subplot(3,2,2)
ax2.imshow(magnitude_spectrum, cmap='gray')
ax2.title.set_text('FFT of image')
ax3 = fig.add_subplot(3,2,3)
ax3.imshow(fshift_mask_mag, cmap='gray')
ax3.title.set_text('HPF FFT + Mask')
ax4 = fig.add_subplot(3,2,4)
ax4.imshow(img_back, cmap='gray')
ax4.title.set_text('After HPF Filter')
ax3 = fig.add_subplot(3,2,5)
ax3.imshow(fshift_mask_mag1, cmap='gray')
ax3.title.set_text('LPF FFT + Mask')
ax4 = fig.add_subplot(3,2,6)
ax4.imshow(img_back1, cmap='gray')
ax4.title.set_text('After LPF Filter')
plt.show()

from scipy.fftpack import dct, idct

# implement 2D DCT
def dct2(a):
    return dct(dct(a.T, norm='ortho').T, norm='ortho')

# implement 2D IDCT
def idct2(a):
    return idct(idct(a.T, norm='ortho').T, norm='ortho')    

from skimage.io import imread
from skimage.color import rgb2gray
import numpy as np
import matplotlib.pylab as plt

# read lena RGB image and convert to grayscale
im = rgb2gray(imread('img10.jpg')) 
imF = dct2(im)
im1 = idct2(imF)

# check if the reconstructed image is nearly equal to the original image
np.allclose(im, im1)
# True

# plot original and reconstructed images with matplotlib.pylab
#plt.gray()
plt.figure(figsize=(21,7), dpi=80)
plt.subplot(131), plt.imshow(im), plt.axis('off'), plt.title('Original image', size=20)
plt.subplot(132), plt.imshow(imF), plt.axis('off'), plt.title('DCT image', size=20)
plt.subplot(133), plt.imshow(im1), plt.axis('off'), plt.title('Reconstructed image IDCT', size=20)
plt.show()

"""# ***EXP 6 IMAGE COMPRESSION USING DCT/DWT***"""

from scipy.fftpack import dct, idct

# implement 2D DCT
def dct2(a):
    return dct(dct(a.T, norm='ortho').T, norm='ortho')

# implement 2D IDCT
def idct2(a):
    return idct(idct(a.T, norm='ortho').T, norm='ortho')    

from skimage.io import imread
from skimage.color import rgb2gray
import numpy as np
import matplotlib.pylab as plt

# read lena RGB image and convert to grayscale
im = rgb2gray(imread('img10.jpg')) 
imF = dct2(im)
im1 = idct2(imF)

# check if the reconstructed image is nearly equal to the original image
np.allclose(im, im1)
# True

# plot original and reconstructed images with matplotlib.pylab
#plt.gray()
plt.figure(figsize=(21,7), dpi=80)
plt.subplot(131), plt.imshow(im), plt.axis('off'), plt.title('Original image', size=20)
plt.subplot(132), plt.imshow(imF), plt.axis('off'), plt.title('DCT image', size=20)
plt.subplot(133), plt.imshow(im1), plt.axis('off'), plt.title('Reconstructed image IDCT', size=20)
plt.show()

"""# ***EXP 7 Edge Detection*** """

import cv2

# Read the original image
img = cv2.imread('img16.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img_gaussian = cv2.GaussianBlur(gray,(3,3),0)

# Sobel Edge Detection
kernelsx = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])
kernelsy = np.array([[1,0,-1],[2,0,-2],[1,0,-1]])
sobelx = cv2.filter2D(img_gaussian, -1, kernelsx)
sobely = cv2.filter2D(img_gaussian, -1, kernelsy)



img = cv2.imread('img16.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img_gaussian = cv2.GaussianBlur(gray,(3,3),0)
#prewitt Edge Detection
kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])
kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])
img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)
img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)

# Display Edge Detection Images
plt.figure(figsize=(21,10), dpi=80)
plt.subplot(231), plt.imshow(sobelx), plt.axis('off'), plt.title('Sobel X', size=20)
plt.subplot(232), plt.imshow(sobely), plt.axis('off'), plt.title('Sobel Y', size=20)
plt.subplot(233), plt.imshow(sobelx + sobely), plt.axis('off'), plt.title('Sobel XY', size=20)
plt.subplot(234), plt.imshow(img_prewittx), plt.axis('off'), plt.title('Prewitt X', size=20)
plt.subplot(235), plt.imshow(img_prewitty), plt.axis('off'), plt.title('Prewitt Y', size=20)
plt.subplot(236), plt.imshow(img_prewittx + img_prewitty), plt.axis('off'), plt.title('Prewitt XY', size=20)
plt.show()
# Canny Edge Detection
print("Canny Edge Detection")
edges = cv2.Canny(image=img_gaussian, threshold1=100, threshold2=200) # Canny Edge Detection
# Display Canny Edge Detection Image
cv2_imshow(edges)

"""# ***EXP 8 Image Thresholding***"""

import cv2
import numpy as np

img = cv2.imread('img17.jpg',0) 
m,n = img.shape
T1 = 128
T2 = 255
  
img_thresh_back = np.zeros((m,n), dtype = int)
   
for i in range(m):
      
    for j in range(n):
        if T1 < img[i,j] < T2: 
          img_thresh_back[i,j]= 255
        else:
          img_thresh_back[i,j] = img[i,j]
  
# Convert array to  png image
plt.figure(figsize=(14,7), dpi=80)
plt.subplot(121), plt.imshow(img), plt.axis('off'), plt.title('Original image', size=10)
plt.subplot(122), plt.imshow(img_thresh_back), plt.axis('off'), plt.title('Image after Threshold', size=10)

"""# ***EXP 9 Morphological Operations***"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
img = cv2.imread('img18.jpg',cv2.IMREAD_COLOR)
erosion = cv2.erode(img,kernel,iterations = 1)
dilation = cv2.dilate(img,kernel,iterations = 1)
opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)
closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)
gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)
dil_ero = cv2.erode(dilation,kernel,iterations = 1)
ero_dil = cv2.dilate(erosion,kernel,iterations = 1)
plt.figure(figsize=(20,5), dpi=80)

plt.subplot(251), plt.imshow(erosion), plt.axis('off'), plt.title('Erosion', size=10)
plt.subplot(252), plt.imshow(dilation), plt.axis('off'), plt.title('Dilation', size=10)
plt.subplot(253), plt.imshow(opening), plt.axis('off'), plt.title('Opening', size=10)
plt.subplot(254), plt.imshow(closing), plt.axis('off'), plt.title('Closing', size=10)
plt.subplot(255), plt.imshow(gradient), plt.axis('off'), plt.title('Gradient', size=10)
plt.subplot(259), plt.imshow(dil_ero), plt.axis('off'), plt.title('dilation, then erosion', size=10)
plt.subplot(258), plt.imshow(ero_dil), plt.axis('off'), plt.title('erosion, then dilation', size=10)

"""# ***EXP 10 Pseudocolouring***"""

from google.colab.patches import cv2_imshow
import cv2 
plt.figure(figsize=(10,20), dpi=80)
im_gray = cv2.imread("img19.jpg", cv2.IMREAD_GRAYSCALE)
im_color1 = cv2.applyColorMap(im_gray, cv2.COLORMAP_JET)
im_color2 = cv2.applyColorMap(im_gray, cv2.COLORMAP_HSV)
im_color3 = cv2.applyColorMap(im_gray, cv2.COLORMAP_SUMMER)
im_color4 = cv2.applyColorMap(im_gray, cv2.COLORMAP_SPRING)
im_color5 = cv2.applyColorMap(im_gray, cv2.COLORMAP_COOL)
im_color6 = cv2.applyColorMap(im_gray, cv2.COLORMAP_AUTUMN)
im_color7 = cv2.applyColorMap(im_gray, cv2.COLORMAP_OCEAN)
im_color8 = cv2.applyColorMap(im_gray, cv2.COLORMAP_HOT)
cv2_imshow(im_gray)
plt.subplot(421), plt.imshow(im_color1), plt.axis('off'), plt.title('COLORMAP_JET', size=10)
plt.subplot(422), plt.imshow(im_color2), plt.axis('off'), plt.title('COLORMAP_HSV', size=10)
plt.subplot(423), plt.imshow(im_color3), plt.axis('off'), plt.title('COLORMAP_SUMMER', size=10)
plt.subplot(424), plt.imshow(im_color4), plt.axis('off'), plt.title('COLORMAP_SPRING', size=10)
plt.subplot(425), plt.imshow(im_color5), plt.axis('off'), plt.title('COLORMAP_COOL', size=10)
plt.subplot(426), plt.imshow(im_color6), plt.axis('off'), plt.title('COLORMAP_AUTUMN', size=10)
plt.subplot(427), plt.imshow(im_color7), plt.axis('off'), plt.title('COLORMAP_OCEAN', size=10)
plt.subplot(428), plt.imshow(im_color8), plt.axis('off'), plt.title('COLORMAP_HOT', size=10)

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap


x = np.arange(0, np.pi, 0.1)
y = np.arange(0, 2 * np.pi, 0.1)
X, Y = np.meshgrid(x, y)

colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]
n_bins = [10,255]
cmap_name = 'my_list'
fig, axs = plt.subplots(1, 2, figsize = (6, 9))
fig.subplots_adjust(left = 0.02, bottom = 0.06, right = 0.95, top = 0.94, wspace = 0.05)
for n_bin, ax in zip(n_bins, axs.ravel()):
  cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N = n_bin)
  im = ax.imshow(im_gray, origin = 'lower', cmap = cmap)
  ax.set_title("N bins: %s" % n_bin)
  #fig.colorbar(im, ax = ax)

"""# ***EXP 11 File Formats***"""

import cv2
import numpy as np
from matplotlib import pyplot as plt
from PIL import Image

img25 = Image.open('img25mb.bmp').convert('RGB')
img26 = Image.open('img26_16cb.bmp').convert('RGB')
img27 = Image.open('img27_256cb.bmp').convert('RGB')
img28 = Image.open('img28_24bb.bmp').convert('RGB')
img29 = Image.open('img29_jpeg.jpg').convert('RGB')
img30 = Image.open("img30_gif.gif").convert('RGB')
img31 = Image.open('img31_tiff.tif').convert('RGB')
img32 = Image.open('img32_png.png').convert('RGB')


plt.figure(figsize=(20,5), dpi=80)
plt.figure(figsize=(20,5), dpi=80).suptitle('EXTRACTION OF BMP HEADER AND COMPARISON OF VARIOUS IMAGE FILE FORMATS', fontsize=16)
plt.subplot(251), plt.imshow(img25), plt.axis('off'), plt.title('Monochrome Bitmap', size=10)
plt.subplot(252), plt.imshow(img26), plt.axis('off'), plt.title('16 Color Bitmap', size=10)
plt.subplot(253), plt.imshow(img27), plt.axis('off'), plt.title('256 Color Bitmap', size=10)
plt.subplot(254), plt.imshow(img28), plt.axis('off'), plt.title('24 Bit Bitmap', size=10)
plt.subplot(255), plt.imshow(img29), plt.axis('off'), plt.title('JPEG', size=10)
plt.subplot(256), plt.imshow(img30), plt.axis('off'), plt.title('GIF', size=10)
plt.subplot(257), plt.imshow(img31), plt.axis('off'), plt.title('TIF', size=10)
plt.subplot(258), plt.imshow(img32), plt.axis('off'), plt.title('PNG', size=10)

"""## **Project Based Learning**"""

import cv2
img = cv2.imread('/content/original 1.bmp',1)
cv2.imwrite('a.jpg',img)

# Import packages
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
img = cv2.imread('a.jpg')
print(img.shape) # Print image shape
cv2_imshow(img)
# Cropping an image
cropped_image = img[70:700, 130:580]
# Display cropped image
cv2_imshow(cropped_image)
# Save the cropped image
cv2.imwrite("Cropped Image.jpg", cropped_image)

import numpy as np
img_dil = cv2.imread('/content/Cropped Image.jpg')
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
chromo_dilate = cv2.dilate(img_dil,kernel,iterations = 1)
cv2.imwrite("chromosomeDilated.jpg", chromo_dilate)
cv2_imshow(chromo_dilate)

"""#### Thresholding"""

import cv2
import numpy as np

img = cv2.imread('/content/chromosomeDilated.jpg',0) 
m,n = img.shape
T1 = 70
T2 = 255
  
img_thresh_back = np.zeros((m,n), dtype = int)
   
for i in range(m):
      
    for j in range(n):
        if T1 < img[i,j] < T2: 
          img_thresh_back[i,j]= 255
        else:
          img_thresh_back[i,j] = img[i,j]

cv2_imshow(img_thresh_back)
cv2.imwrite("chromosome_thresh.jpg",img_thresh_back)

"""##### Negative"""

import cv2
import numpy as np
# Load the image
img = cv2.imread('/content/chromosome_thresh.jpg')
# Check the datatype of the image
print(img.dtype)
# Subtract the img from max value(calculated from dtype)
img_neg = 255 - img
# Show the image
cv2_imshow(img_neg)
cv2.imwrite('img_negative.jpg',img_neg)

"""### Contour Plotting"""

import cv2


image= cv2.imread('/content/chromosome_thresh.jpg')
original_image= image

gray= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)

edges= cv2.Canny(gray, 50,200)

contours, hierarchy= cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

def get_contour_areas(contours):

    all_areas= []

    for cnt in contours:
        area= cv2.contourArea(cnt)
        all_areas.append(area)

    return all_areas


sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)


largest_item= sorted_contours[0]
second_largest = sorted_contours[1]
cv2.drawContours(original_image, largest_item, -1, (255,0,0),2)
cv2.drawContours(original_image, second_largest, -1, (255,0,0),2)
cv2_imshow(original_image)
cv2.imwrite("metaphase_contour.jpg",original_image)

"""# Karyotype"""

import cv2
img = cv2.imread('/content/karyotype 1.bmp',1)
cv2.imwrite('b.jpg',img)

import cv2
import numpy as np

img = cv2.imread('/content/b.jpg',0) 
m,n = img.shape
T1 = 0
T2 = 230
  
img_thresh_back = np.zeros((m,n), dtype = int)
   
for i in range(m):
      
    for j in range(n):
        if T1 < img[i,j] <= T2: 
          img_thresh_back[i,j]= 0
        else:
          img_thresh_back[i,j] = img[i,j]

cv2_imshow(img_thresh_back)
cv2.imwrite("chromosome_borderbox.jpg",img_thresh_back)

import cv2
import numpy as np
# Load the image
img = cv2.imread('/content/chromosome_borderbox.jpg')
# Check the datatype of the image
print(img.dtype)
# Subtract the img from max value(calculated from dtype)
img_neg = 255 - img
# Show the image
cv2_imshow(img_neg)
cv2.imwrite('img_negative_border.jpg',img_neg)

img1 = cv2.imread("/content/b.jpg")
img2 = cv2.imread("/content/img_negative_border.jpg")
bitwise_and = cv2.bitwise_and(img2, img1)
cv2_imshow(bitwise_and)
cv2.imwrite('c.jpg',bitwise_and)

import numpy as np
img_dil = cv2.imread('c.jpg')
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1,1))
chromo_dilate1 = cv2.dilate(img_dil,kernel,iterations = 1)
cv2.imwrite("cdk.jpg", chromo_dilate1)
cv2_imshow(chromo_dilate1)

import cv2
import numpy as np

img = cv2.imread('/content/cdk.jpg',0) 
m,n = img.shape
T1 = 35
T2 = 255
  
img_thresh_back = np.zeros((m,n), dtype = int)
   
for i in range(m):
      
    for j in range(n):
        if T1 < img[i,j] < T2: 
          img_thresh_back[i,j]= 255
        else:
          img_thresh_back[i,j] = img[i,j]

cv2_imshow(img_thresh_back)
cv2.imwrite("ctk.jpg",img_thresh_back)

import cv2


image= cv2.imread('/content/ctk.jpg')
original_image1= image

gray= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)

edges= cv2.Canny(gray, 50,200)

contours, hierarchy= cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

def get_contour_areas(contours):

    all_areas= []

    for cnt in contours:
        area= cv2.contourArea(cnt)
        all_areas.append(area)

    return all_areas


sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)


largest_item= sorted_contours[0]
second_largest = sorted_contours[1]
cv2.drawContours(original_image1, second_largest, -1, (255,0,0),2)
cv2.drawContours(original_image1, sorted_contours[2], -1, (255,0,0),2)
cv2_imshow(original_image1)
cv2.imwrite("karyo_contour.jpg",original_image1)

import matplotlib.pyplot as plt
plt.figure(figsize=(20,10), dpi=80)
plt.figure(figsize=(20,10), dpi=80).suptitle('DIVP PROJECT BASED LEARNING', fontsize=20)
plt.subplot(121), plt.imshow(cv2.imread('/content/karyo_contour.jpg')), plt.axis('off'), plt.title('Karyotypes', size=15)
plt.subplot(122), plt.imshow(cv2.imread('/content/metaphase_contour.jpg')), plt.axis('off'), plt.title('Metaphase', size=15)